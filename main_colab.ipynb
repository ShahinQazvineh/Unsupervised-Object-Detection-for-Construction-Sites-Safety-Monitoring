{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientifically Sound Unsupervised PPE Detection (Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# --- Path Setup ---\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "from config import CONFIG\n",
    "from data_utils import prepare_dataset\n",
    "from unsupervised_trainer import UnsupervisedTrainer\n",
    "from discovery_processor import DiscoveryProcessor\n",
    "from violation_processor import ViolationProcessor\n",
    "\n",
    "print(f\"Project root set to: {CONFIG['project_root_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "image_paths, labels = prepare_dataset(CONFIG['training']['data_fraction'])\n",
    "\n",
    "# Custom Dataset and DINO Augmentations\n",
    "class DataAugmentationDINO(object):\n",
    "    # ... (omitted for brevity - same as before) ...\n",
    "\n",
    "class PpeDataset(Dataset):\n",
    "    # ... (omitted for brevity - same as before) ...\n",
    "\n",
    "transform = DataAugmentationDINO()\n",
    "dataset = PpeDataset(image_paths, labels, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=CONFIG['training']['batch_size'], shuffle=True)\n",
    "\n",
    "# --- Training --- \n",
    "# Set to False to skip training and use a pretrained model\n",
    "run_training = False\n",
    "if run_training:\n",
    "    trainer = UnsupervisedTrainer(CONFIG)\n",
    "    trainer.train(data_loader)\n",
    "else:\n",
    "    print(\"Skipping training. A pretrained DINOv2 model will be used for discovery.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unsupervised Object Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model for discovery\n",
    "# If training was run, this would load the fine-tuned model.\n",
    "# If not, it loads the default pretrained DINOv2.\n",
    "model_path = CONFIG['checkpoint_dir_abs'] / 'latest_checkpoint.pt'\n",
    "discovery_processor = DiscoveryProcessor(CONFIG, model_path=model_path if run_training and model_path.exists() else None)\n",
    "\n",
    "# Select a sample image from the validation set\n",
    "valid_image_paths = [p for p in image_paths if 'valid' in str(p)]\n",
    "if valid_image_paths:\n",
    "    sample_image_path = random.choice(valid_image_paths)\n",
    "    sample_image = cv2.imread(sample_image_path)\n",
    "    sample_image_rgb = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Discover objects using the new method\n",
    "    discovered_objects, masks = discovery_processor.discover_objects(sample_image_rgb, n_clusters=4)\n",
    "\n",
    "    # Visualize the results\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(sample_image_rgb)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(masks, cmap='viridis')\n",
    "    plt.title('Discovered Segments')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(sample_image_rgb)\n",
    "    for obj in discovered_objects:\n",
    "        x1, y1, x2, y2 = obj['box']\n",
    "        plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, edgecolor='red', facecolor='none', lw=2))\n",
    "        plt.text(x1, y1 - 5, f\"Cluster {obj['cluster_id']}\", color='white', backgroundcolor='red')\n",
    "    plt.title('Discovered Bounding Boxes')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No validation images found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validation: Mapping Clusters to Classes and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxA, boxB):\n",
    "    # ... (omitted for brevity - same as before) ...\n",
    "\n",
    "def map_clusters_to_classes(discovery_processor, image_paths, labels):\n",
    "    # ... (Implementation in next cell)\n",
    "    pass\n",
    "\n",
    "def evaluate_discovery(discovery_processor, cluster_class_map, image_paths, labels):\n",
    "    # ... (Implementation in next cell)\n",
    "    pass\n",
    "\n",
    "# --- Run Validation ---\n",
    "print(\"Mapping unsupervised clusters to semantic classes...\")\n",
    "valid_indices = [i for i, p in enumerate(image_paths) if 'valid' in str(p)]\n",
    "valid_images = [image_paths[i] for i in valid_indices]\n",
    "valid_labels = [labels[i] for i in valid_indices]\n",
    "\n",
    "# This is a compute-intensive step, so we'll run on a subset\n",
    "subset_size = 50\n",
    "cluster_class_map = map_clusters_to_classes(discovery_processor, valid_images[:subset_size], valid_labels[:subset_size])\n",
    "print(f\"Cluster to Class Map: {cluster_class_map}\")\n",
    "\n",
    "print(\"\\nEvaluating discovery performance...\")\n",
    "mean_iou = evaluate_discovery(discovery_processor, cluster_class_map, valid_images[:subset_size], valid_labels[:subset_size])\n",
    "print(f\"\\nMean IoU on Validation Set: {mean_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Implementation of Validation Functions ---\n",
    "\n",
    "def map_clusters_to_classes(discovery_processor, image_paths, labels, n_clusters=4):\n",
    "    num_classes = len(CONFIG['discovery']['class_map'])\n",
    "    cost_matrix = np.zeros((n_clusters, num_classes))\n",
    "\n",
    "    for img_path, label_list in zip(image_paths, labels):\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        discovered_objects, _ = discovery_processor.discover_objects(img_rgb, n_clusters=n_clusters)\n",
    "        \n",
    "        for gt_obj in label_list:\n",
    "            gt_box = gt_obj['box']\n",
    "            gt_class_id = gt_obj['class_id']\n",
    "            for pred_obj in discovered_objects:\n",
    "                pred_box = pred_obj['box']\n",
    "                iou = calculate_iou(gt_box, pred_box)\n",
    "                cost_matrix[pred_obj['cluster_id'], gt_class_id] -= iou # Negative because we want to maximize IoU\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    return {r: c for r, c in zip(row_ind, col_ind)}\n",
    "\n",
    "def evaluate_discovery(discovery_processor, cluster_class_map, image_paths, labels, n_clusters=4):\n",
    "    total_iou = 0\n",
    "    gt_box_count = 0\n",
    "\n",
    "    for img_path, label_list in zip(image_paths, labels):\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        discovered_objects, _ = discovery_processor.discover_objects(img_rgb, n_clusters=n_clusters)\n",
    "        \n",
    "        # Map predicted cluster IDs to class IDs\n",
    "        for obj in discovered_objects:\n",
    "            obj['class_id'] = cluster_class_map.get(obj['cluster_id'], -1)\n",
    "\n",
    "        for gt_obj in label_list:\n",
    "            gt_box = gt_obj['box']\n",
    "            gt_class_id = gt_obj['class_id']\n",
    "            best_iou = 0\n",
    "            for pred_obj in discovered_objects:\n",
    "                if pred_obj['class_id'] == gt_class_id:\n",
    "                    iou = calculate_iou(gt_box, pred_obj['box'])\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "            total_iou += best_iou\n",
    "            gt_box_count += 1\n",
    "\n",
    "    return total_iou / gt_box_count if gt_box_count > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. End-to-End Inference and Violation Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_processor = ViolationProcessor(CONFIG)\n",
    "\n",
    "# --- Video Processing ---\n",
    "video_path = 'path/to/your/video.mp4' # <--- CHANGE THIS PATH\n",
    "\n",
    "if not os.path.exists(video_path):\n",
    "    print(f\"Video file not found at {video_path}. Using single image for inference demo.\")\n",
    "    # Use the sample image from before for a single-frame demo\n",
    "    discovered_objects, _ = discovery_processor.discover_objects(sample_image_rgb, n_clusters=4)\n",
    "    for obj in discovered_objects:\n",
    "        obj['class_id'] = cluster_class_map.get(obj['cluster_id'], -1)\n",
    "    \n",
    "    violations = violation_processor.process_violations(discovered_objects, sample_image_rgb)\n",
    "    print(f\"Violations found in sample image: {violations}\")\n",
    "\n",
    "else:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 1. Discover objects\n",
    "        discovered_objects, _ = discovery_processor.discover_objects(frame_rgb, n_clusters=4)\n",
    "        \n",
    "        # 2. Map cluster IDs to class IDs\n",
    "        for obj in discovered_objects:\n",
    "            obj['class_id'] = cluster_class_map.get(obj['cluster_id'], -1)\n",
    "        \n",
    "        # 3. Process for violations\n",
    "        violations = violation_processor.process_violations(discovered_objects, frame_rgb)\n",
    "        \n",
    "        # 4. (Optional) Visualize the output\n",
    "        # ... (visualization logic can be added here) ...\n",
    "        \n",
    "    cap.release()\n",
    "    print(\"Video processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
